######################################################
#
# Oracle Basic Monitoring
#
######################################################

[[metric]]
context = "logins_last_5h"
metricsdesc = { dbusername="DB Username", client_program_name="Client Program Name", timestamp="Timestamp", userhost="Userhost", dbuser_logins="Logins last 5h"}
labels= ["dbusername", "client_program_name", "timestamp", "userhost"]
request = "select CURRENT_USER,client_program_name,to_char(event_timestamp,'yyyy-mm-dd hh24') as timestamp,HOST_NAME,count(*) as dbuser_logins from AUDSYS.AUD$UNIFIED where event_timestamp between sysdate-1/2  and trunc(sysdate,'hh24') and ACTION = 100 group by CURRENT_USER,client_program_name,to_char(event_timestamp,'yyyy-mm-dd hh24'),HOST_NAME;"
ignorezeroresult = true
metricstype = { dbuser_logins = "counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "recovery_space_used"
metricsdesc = { file_type="Typ", percent_space_used="Usage in percent"}
labels= ["file_type", "percent_space_used"]
request = "select file_type, percent_space_used from v$recovery_area_usage"
metricstype = { percent_space_used = "counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "recovery_space_reclaimable"
metricsdesc = { file_type="Typ", percent_space_reclaimable="reclaimable space"}
labels= ["file_type", "percent_space_reclaimable"]
request = "select file_type, percent_space_reclaimable from v$recovery_area_usage"
metricstype = { percent_space_reclaimable = "counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "recovery_files"
metricsdesc = { file_type="Typ", number_of_files="Number of files"}
labels= ["file_type", "number_of_files"]
request = "select file_type, number_of_files from v$recovery_area_usage"
metricstype = { number_of_files = "counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "failed_logins_last_5h"
metricsdesc = { dbusername="DB Username", client_program_name="Client Program Name", timestamp="Timestamp", userhost="Userhost", failed_dbuser_logins="Logins last 5h"}
labels= ["dbusername", "client_program_name", "timestamp", "userhost"]
request = "select CURRENT_USER,client_program_name,to_char(event_timestamp,'yyyy-mm-dd hh24') as timestamp, HOST_NAME, count(*) as failed_dbuser_logins from AUDSYS.AUD$UNIFIED where event_timestamp between sysdate-1/6  and trunc(sysdate,'hh24') and ACTION = 100 and return_code !=0 group by CURRENT_USER,client_program_name,to_char(event_timestamp,'yyyy-mm-dd hh24'),HOST_NAME"
metricstype = { failed_dbuser_logins = "counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "count_db_blocking_Locks"
metricsdesc = { count_db_blocks="Gauge metric with count of Blocking Sessions." }
request = "select count(*) as count_db_blocks from v$session where blocking_session is not NULL"
metricstype = { count_db_blocks="counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "slow_queries"
metricsdesc = { p95_time_usecs= "Gauge metric with percentile 95 of elapsed time.", p99_time_usecs= "Gauge metric with percentile 99 of elapsed time." }
request = "select  percentile_disc(0.95)  within group (order by elapsed_time) as p95_time_usecs, percentile_disc(0.99)  within group (order by elapsed_time) as p99_time_usecs from v$sql where last_active_time >= sysdate - 5/(24*60)"
metricstype = { p95_time_usecs="counter", p99_time_usecs="counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "big_queries"
metricsdesc = { p95_rows= "Gauge metric with percentile 95 of returned rows.", p99_rows= "Gauge metric with percentile 99 of returned rows." }
request = "select  percentile_disc(0.95)  within group (order by rownum) as p95_rows, percentile_disc(0.99)  within group (order by rownum) as p99_rows from v$sql where last_active_time >= sysdate - 5/(24*60)"
metricstype = { p95_rows="counter", p99_rows="counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "cache_hit_ratio"
metricsdesc = {percentage="Gauge metric with the cache hit ratio."}
request = "select Round(((Sum(Decode(a.name, 'consistent gets', a.value, 0)) + Sum(Decode(a.name, 'db block gets', a.value, 0)) - Sum(Decode(a.name, 'physical reads', a.value, 0))  )/ (Sum(Decode(a.name, 'consistent gets', a.value, 0)) + Sum(Decode(a.name, 'db block gets', a.value, 0)))) *100,2) as percentage FROM v$sysstat a"
# Test mit prometheus_read ok.

[[metric]]
context = "startup"
metricsdesc = {time_seconds="Database startup time in seconds."}
request = "SELECT (SYSDATE - STARTUP_TIME) * 24 * 60 * 60 AS time_seconds FROM V$INSTANCE"
# Test mit prometheus_read ok.


######################################################
#
# opentext Archive Center
#
######################################################

[[metric]]
context = "otac_adm_alert_messages"
metricsdesc = { label_status="Status"}
labels = [ "IDNO", "MSGCLASS", "COMPNAME", "Timestamp", "Severity"]
request = "select IDNO, MSGCLASS,  COMPNAME, Timestamp, Severity from otac.ADM_ALERT where FLAGS != 1"
ignorezeroresult = true
metricstype = { IDNO = "counter" }
# Test mit prometheus_read ok.

[[metric]]
context = "otac_ds_job_count"
metricsdesc = { count_write_job="Open Write Jobs to Storage"}
labels = [ "nodename" ]
request = "select count(*) as count_write_job, nodename from otac.ds_job group by nodename"
ignorezeroresult = true
# Test mit prometheus_read ok.

[[metric]]
context = "otac_size_user_segments_top100"
metricsdesc = {table_bytes="Gauge metric with the size of the tables in user segments."}
labels = ["segment_name"]
request = "select * from (select segment_name,sum(bytes) as table_bytes from DBA_SEGMENTS where owner = 'OTAC' and segment_type='TABLE' group by segment_name) order by table_bytes DESC"
# Test mit prometheus_read ok.